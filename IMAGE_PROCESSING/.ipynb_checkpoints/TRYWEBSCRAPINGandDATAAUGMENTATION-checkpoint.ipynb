{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db965349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search keyword: banana\n",
      "Enter the number of images you want: 5\n",
      "Searching Images....\n",
      "Found 5 images\n",
      "Start downloading...\n",
      "Download Completed!\n"
     ]
    }
   ],
   "source": [
    "# For explanation of this code, you can visit this video: https://www.youtube.com/watch?v=8AyKJxBxx0M&t=172s\n",
    "import os\n",
    "import requests # pip install requests #to sent GET requests\n",
    "from bs4 import BeautifulSoup # pip install bs4 #to parse html(getting data out from html, xml or other markup languages)\n",
    "\n",
    "# user can input a search keyword and the count of images required\n",
    "# download images from google search image\n",
    "Google_Image = 'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'\n",
    "\n",
    "# The User-Agent request header contains a characteristic string \n",
    "# that allows the network protocol peers to identify the application type, \n",
    "# operating system, and software version of the requesting software user agent.\n",
    "# needed for google search\n",
    "u_agnt = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "    'Accept-Encoding': 'none',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "} #write: 'my user agent' in browser to get your browser user agent details\n",
    "\n",
    "Image_Folder = '/Users/HP/Documents/STUDIES/PYTHONCODES/DATASETS/WEBSCRAPING1'\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(Image_Folder):\n",
    "        os.mkdir(Image_Folder)\n",
    "    download_images()\n",
    "\n",
    "def download_images():\n",
    "    data = input('Enter your search keyword: ')\n",
    "    num_images = int(input('Enter the number of images you want: '))\n",
    "    \n",
    "    print('Searching Images....')\n",
    "    \n",
    "    search_url = Google_Image + 'q=' + data #'q=' because its a query\n",
    "    \n",
    "    # request url, without u_agnt the permission gets denied\n",
    "    response = requests.get(search_url, headers=u_agnt)\n",
    "    html = response.text #To get actual result i.e. to read the html data in text mode\n",
    "    \n",
    "    # find all img where class='rg_i Q4LuWd'\n",
    "    b_soup = BeautifulSoup(html, 'html.parser') #html.parser is used to parse/extract features from HTML files\n",
    "    results = b_soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
    "    \n",
    "    #extract the links of requested number of images with 'data-src' attribute and appended those links to a list 'imagelinks'\n",
    "    #allow to continue the loop in case query fails for non-data-src attributes\n",
    "    count = 0\n",
    "    imagelinks= []\n",
    "    for res in results:\n",
    "        try:\n",
    "            link = res['data-src']\n",
    "            imagelinks.append(link)\n",
    "            count = count + 1\n",
    "            if (count >= num_images):\n",
    "                break\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    print(f'Found {len(imagelinks)} images')\n",
    "    print('Start downloading...')\n",
    "\n",
    "    for i, imagelink in enumerate(imagelinks):\n",
    "        # open each image link and save the file\n",
    "        response = requests.get(imagelink)\n",
    "        \n",
    "        imagename = Image_Folder + '/' + data + str(i+1) + '.jpg'\n",
    "        with open(imagename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    print('Download Completed!')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4ae48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search keyword: cat\n",
      "Enter the number of images you want: 10\n",
      "Searching Images....\n",
      "Found 10 images\n",
      "Start downloading...\n",
      "Download Completed!\n"
     ]
    }
   ],
   "source": [
    "Image_Folder = '/Users/HP/Documents/STUDIES/PYTHONCODES/DATASETS/WEBSCRAPING1'\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23672cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23140f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
